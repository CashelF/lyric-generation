{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:55:03.994793Z","iopub.status.busy":"2024-04-29T07:55:03.994052Z","iopub.status.idle":"2024-04-29T07:55:25.765515Z","shell.execute_reply":"2024-04-29T07:55:25.764657Z","shell.execute_reply.started":"2024-04-29T07:55:03.994754Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/davidpekar/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n","from datasets import load_dataset\n","from sklearn.metrics.pairwise import cosine_similarity\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:57:20.860276Z","iopub.status.busy":"2024-04-29T07:57:20.859903Z","iopub.status.idle":"2024-04-29T07:58:50.112510Z","shell.execute_reply":"2024-04-29T07:58:50.111733Z","shell.execute_reply.started":"2024-04-29T07:57:20.860247Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"amishshah/song_lyrics\")\n","dataset = dataset[\"train\"].shuffle(seed=42)\n","subset_size = 25000\n","dataset = dataset.select(range(subset_size))\n","train_test_dataset = dataset.train_test_split(test_size=0.1)\n","train_dataset = train_test_dataset[\"train\"]\n","val_dataset = train_test_dataset[\"test\"]\n","#train_test_dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n","#train_dataset = train_test_dataset[\"train\"]\n","#val_dataset = train_test_dataset[\"test\"]"]},{"cell_type":"markdown","metadata":{},"source":["# Load tokenizer and pre-trained model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:59:49.888862Z","iopub.status.busy":"2024-04-29T07:59:49.888025Z","iopub.status.idle":"2024-04-29T07:59:55.313873Z","shell.execute_reply":"2024-04-29T07:59:55.312951Z","shell.execute_reply.started":"2024-04-29T07:59:49.888825Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n","from datasets import load_dataset\n","\n","# Load tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained(\"./results\")\n","model = GPT2LMHeadModel.from_pretrained(\"./results\")\n","\n","# Ensure that tokenizer has padding token set\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenize Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:00:05.931482Z","iopub.status.busy":"2024-04-29T08:00:05.930493Z","iopub.status.idle":"2024-04-29T08:00:15.234369Z","shell.execute_reply":"2024-04-29T08:00:15.233387Z","shell.execute_reply.started":"2024-04-29T08:00:05.931436Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 22500/22500 [00:26<00:00, 863.34 examples/s]\n","Map: 100%|██████████| 2500/2500 [00:03<00:00, 754.81 examples/s]\n"]}],"source":["# Tokenize the data\n","def tokenize_function(examples):\n","    return tokenizer(examples['lyrics'], truncation=True, padding=True, max_length=512)\n","\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","val_dataset = val_dataset.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Fine-tuning"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:01:27.279888Z","iopub.status.busy":"2024-04-29T08:01:27.279485Z","iopub.status.idle":"2024-04-29T08:01:28.818211Z","shell.execute_reply":"2024-04-29T08:01:28.817370Z","shell.execute_reply.started":"2024-04-29T08:01:27.279857Z"},"trusted":true},"outputs":[],"source":["# Set training arguments\n","training_args = TrainingArguments(\n","    output_dir='./models',\n","    num_train_epochs=4,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=8,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=100,\n",")\n","\n","# Initialize Trainer\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:01:33.636142Z","iopub.status.busy":"2024-04-29T08:01:33.635450Z","iopub.status.idle":"2024-04-29T08:07:46.141276Z","shell.execute_reply":"2024-04-29T08:07:46.139912Z","shell.execute_reply.started":"2024-04-29T08:01:33.636109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device:  cpu\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 100/22500 [01:58<7:00:14,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.7021, 'grad_norm': 2.0258922576904297, 'learning_rate': 1e-05, 'epoch': 0.02}\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 200/22500 [03:51<7:00:23,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.7131, 'grad_norm': 2.1059556007385254, 'learning_rate': 2e-05, 'epoch': 0.04}\n"]},{"name":"stderr","output_type":"stream","text":["  1%|▏         | 300/22500 [05:44<6:53:36,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.663, 'grad_norm': 1.6924552917480469, 'learning_rate': 3e-05, 'epoch': 0.05}\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 400/22500 [07:37<6:59:54,  1.14s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.6041, 'grad_norm': 1.5649513006210327, 'learning_rate': 4e-05, 'epoch': 0.07}\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 500/22500 [09:30<6:54:35,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.6989, 'grad_norm': 2.5242412090301514, 'learning_rate': 5e-05, 'epoch': 0.09}\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 600/22500 [11:26<6:56:47,  1.14s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.7088, 'grad_norm': 1.7427242994308472, 'learning_rate': 4.9772727272727275e-05, 'epoch': 0.11}\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 700/22500 [13:19<6:56:44,  1.15s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.5961, 'grad_norm': 1.8031307458877563, 'learning_rate': 4.9545454545454553e-05, 'epoch': 0.12}\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▎         | 800/22500 [15:13<6:53:20,  1.14s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.6381, 'grad_norm': 1.61652672290802, 'learning_rate': 4.931818181818182e-05, 'epoch': 0.14}\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 900/22500 [17:06<6:47:32,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.7141, 'grad_norm': 1.735072135925293, 'learning_rate': 4.909090909090909e-05, 'epoch': 0.16}\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 1000/22500 [18:58<6:42:47,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.6836, 'grad_norm': 1.3271573781967163, 'learning_rate': 4.886363636363637e-05, 'epoch': 0.18}\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 1100/22500 [20:53<6:43:21,  1.13s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.7017, 'grad_norm': 1.6593340635299683, 'learning_rate': 4.863636363636364e-05, 'epoch': 0.2}\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 1200/22500 [22:46<6:41:32,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.7599, 'grad_norm': 1.875386357307434, 'learning_rate': 4.840909090909091e-05, 'epoch': 0.21}\n"]},{"name":"stderr","output_type":"stream","text":["  6%|▌         | 1242/22500 [23:33<6:47:33,  1.15s/it]"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/transformers/trainer.py:3147\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/accelerate/accelerator.py:2013\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2013\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/Python Projects/lyric generation/venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Check if GPU is available and if not, use CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Device: \", device)\n","\n","model.to(device)\n","# Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["model_path = \"./models\""]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:09:07.569432Z","iopub.status.busy":"2024-04-29T08:09:07.568428Z","iopub.status.idle":"2024-04-29T08:09:08.673851Z","shell.execute_reply":"2024-04-29T08:09:08.672694Z","shell.execute_reply.started":"2024-04-29T08:09:07.569396Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('./models/tokenizer_config.json',\n"," './models/special_tokens_map.json',\n"," './models/vocab.json',\n"," './models/merges.txt',\n"," './models/added_tokens.json')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"]},{"cell_type":"markdown","metadata":{},"source":["# Lyric Generation"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:09:37.666194Z","iopub.status.busy":"2024-04-29T08:09:37.665822Z","iopub.status.idle":"2024-04-29T08:10:02.575527Z","shell.execute_reply":"2024-04-29T08:10:02.574421Z","shell.execute_reply.started":"2024-04-29T08:09:37.666164Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["complete the lyrics about love and loss                                                                                               x3 \n","Love is like a thing                                                                                                                                                                                                                                                                                                           II                                                                                                                                                                                               \n"]}],"source":["# Load the model and tokenizer for text generation\n","from transformers import pipeline\n","\n","# Ensure your model and tokenizer are loaded correctly\n","text_generator = pipeline('text-generation', model=model_path, tokenizer=model_path)\n","\n","# Generate text using the pipeline\n","prompt = \"complete the lyrics about love and loss \"\n","results = text_generator(prompt, max_length=600, truncation=True)\n","print(results[0]['generated_text'])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load in a fine-tuned model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T02:47:12.387669Z","iopub.status.busy":"2024-04-29T02:47:12.386954Z","iopub.status.idle":"2024-04-29T02:47:12.617704Z","shell.execute_reply":"2024-04-29T02:47:12.616529Z","shell.execute_reply.started":"2024-04-29T02:47:12.387636Z"},"trusted":true},"outputs":[],"source":["model = GPT2LMHeadModel.from_pretrained(model_path)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate fine-tuning using perplexity"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["text = '''Hello darkness, my old friend\n","I've come to talk with you again\n","Because a vision softly creeping'''\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T08:11:47.631700Z","iopub.status.busy":"2024-04-29T08:11:47.630977Z","iopub.status.idle":"2024-04-29T08:11:48.690803Z","shell.execute_reply":"2024-04-29T08:11:48.689635Z","shell.execute_reply.started":"2024-04-29T08:11:47.631651Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Perplexity of Pretrained Model: 64.45396423339844\n","Perplexity of Base GPT-2 Model: 122.21576690673828\n"]}],"source":["import torch\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","def calculate_perplexity(model, tokenizer, text):\n","    encode = tokenizer.encode(text, return_tensors='pt')\n","    with torch.no_grad():\n","        outputs = model(encode, labels=encode)\n","        loss = outputs[0]\n","\n","    return torch.exp(loss).item()\n","\n","# Load models and tokenizer\n","model_pretrained = GPT2LMHeadModel.from_pretrained(model_path)\n","model_base = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","# Calculate perplexity\n","perplexity_pretrained = calculate_perplexity(model_pretrained, tokenizer, text)\n","perplexity_base = calculate_perplexity(model_base, tokenizer, text)\n","\n","print(f'Perplexity of Pretrained Model: {perplexity_pretrained}')\n","print(f'Perplexity of Base GPT-2 Model: {perplexity_base}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate fine-tuning using rouge-score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["masked_song_prompt = \"Hello darkness, my old ****, I've come to **** with you again, Because a vision softly ****,\"\n","unmasked_song_prompt = '''Hello darkness, my old friend\n","I've come to talk with you again\n","Because a vision softly creeping'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:22:18.632604Z","iopub.status.busy":"2024-04-29T04:22:18.632280Z","iopub.status.idle":"2024-04-29T04:22:18.974489Z","shell.execute_reply":"2024-04-29T04:22:18.973162Z","shell.execute_reply.started":"2024-04-29T04:22:18.632570Z"},"trusted":true},"outputs":[],"source":["from rouge_score import rouge_scorer\n","\n","# Load models and tokenizer\n","model_base = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","text_generator_finetuned = pipeline('text-generation', model=model_path, tokenizer=model_path)\n","generated_lyrics_finetuned = text_generator(masked_song_prompt, max_length=500)[0]['generated_text']\n","\n","text_generator_base = pipeline('text-generation', model=model_base, tokenizer=tokenizer)\n","generated_lyrics_base = text_generator(masked_song_prompt, max_length=500)[0]['generated_text']\n","\n","# Initialize the ROUGE scorer, you can specify which rouge types to calculate\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","\n","# Function to calculate average scores\n","def calculate_average_rouge(generated, references):\n","    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n","    \n","    for gen, ref in zip(generated, references):\n","        score = scorer.score(ref, gen)\n","        for key in scores.keys():\n","            scores[key].append(score[key].fmeasure)\n","    \n","    average_scores = {key: sum(values) / len(values) for key, values in scores.items()}\n","    return average_scores\n","\n","# Calculate average ROUGE scores\n","average_scores_base = calculate_average_rouge(generated_lyrics_base, unmasked_song_prompt)\n","print(\"Average ROUGE scores for base GPT-2:\", average_scores_base)\n","\n","average_scores_finetuned = calculate_average_rouge(generated_lyrics_finetuned, unmasked_song_prompt)\n","print(\"Average ROUGE scores for finetuned model:\", average_scores_finetuned)\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Complete these lyrics: Underneath the stars that', 'Complete these lyrics: When the rain starts falling and', 'Complete these lyrics: Beside the flowing river where', 'Complete these lyrics: Amid the echoes of the old town, the', 'Complete these lyrics: As the leaves turn golden, there', 'Complete these lyrics: Through the winding streets of my memories,', 'Complete these lyrics: Under the shadow of the old bridge, we', 'Complete these lyrics: When the lights go out and', 'Complete these lyrics: Across the endless sea, the wind', 'Complete these lyrics: Beneath the wide sky where', 'Complete these lyrics: Along the path less traveled by,', 'Complete these lyrics: Beyond the horizon where dreams', 'Complete these lyrics: Through the whispering fields of green,', 'Complete these lyrics: On the balcony at midnight, I', 'Complete these lyrics: In the silence of the morning,', 'Complete these lyrics: Beside the crackling fire, we', 'Complete these lyrics: When the curtain falls and', 'Complete these lyrics: In the deepest of forests,', 'Complete these lyrics: Beneath the bustling city lights,', 'Complete these lyrics: With every heartbeat, I', 'Complete these lyrics: As the storm clouds gather,', 'Complete these lyrics: Amidst the fading colors of the sunset,', 'Complete these lyrics: Under the spell of the full moon,', 'Complete these lyrics: Along the frozen shores,', 'Complete these lyrics: Between the pages of a forgotten book,', 'Complete these lyrics: Beneath the starry sky, as', 'Complete these lyrics: Wrapped in the cold night air,', 'Complete these lyrics: In the quiet hours before dawn,', 'Complete these lyrics: On the edge of a dream, where', 'Complete these lyrics: Under the burning sun that', 'Complete these lyrics: Within the walls of this ancient castle,', 'Complete these lyrics: Beyond the fields that', 'Complete these lyrics: Underneath the weight of this world,', 'Complete these lyrics: As the river flows and', 'Complete these lyrics: Through the valley of shadows,', 'Complete these lyrics: In the grip of the cold winter,', 'Complete these lyrics: Amidst the clashing of our words,', 'Complete these lyrics: On the streets where history', 'Complete these lyrics: With the fading light of the evening,', 'Complete these lyrics: In the hush of the night, where', 'Complete these lyrics: By the old mill stream where', 'Complete these lyrics: As the clock strikes midnight,', 'Complete these lyrics: Beyond the misty mountains,', 'Complete these lyrics: Through the sorrow and the pain,', 'Complete these lyrics: In the echo of ancient chants,', 'Complete these lyrics: On a journey to nowhere,', 'Complete these lyrics: Amidst the crowds of yesterday,', \"Complete these lyrics: In the mirror's reflection, I\", 'Complete these lyrics: At the break of dawn,', 'Complete these lyrics: Where the wild roses grow,', 'Complete these lyrics: In the gleam of the fading light,', 'Complete these lyrics: By the calm waters of the lake,', 'Complete these lyrics: Beneath the veil of twilight,', 'Complete these lyrics: On the wings of the morning,', 'Complete these lyrics: Through the storm and the rain,', 'Complete these lyrics: As the world turns slowly,', 'Complete these lyrics: Beneath the ancient oak,', 'Complete these lyrics: On the road that leads to nowhere,', 'Complete these lyrics: In the depths of your eyes,', 'Complete these lyrics: At the end of the journey,', 'Complete these lyrics: With the whisper of the wind,', 'Complete these lyrics: Under the canopy of stars,', 'Complete these lyrics: In the labyrinth of my thoughts,', 'Complete these lyrics: When the shadows fall and', 'Complete these lyrics: As we dance through the night,', 'Complete these lyrics: On the shores of a distant land,', 'Complete these lyrics: In the twilight of our years,', 'Complete these lyrics: With each passing storm,', 'Complete these lyrics: By the fading embers of the fire,', 'Complete these lyrics: Through the pages of our days,', 'Complete these lyrics: Under the veil of the night sky,', 'Complete these lyrics: In the whispers of the forgotten,', 'Complete these lyrics: At the edge of the sea,', 'Complete these lyrics: Where the streets have no name,', 'Complete these lyrics: In the flow of the endless river,', 'Complete these lyrics: As the stars begin to gather,', 'Complete these lyrics: On the brink of the unknown,', 'Complete these lyrics: Within the echoes of silence,', 'Complete these lyrics: Through the mist and the darkness,', 'Complete these lyrics: Underneath the cascade of falling leaves,', 'Complete these lyrics: As the fireflies light the night,', 'Complete these lyrics: By the light of the silvery moon,', 'Complete these lyrics: Amidst the ruins of once-great cities,', 'Complete these lyrics: On the breath of the morning breeze,', 'Complete these lyrics: In the shadow of the setting sun,', 'Complete these lyrics: Through the dance of the firelight,', 'Complete these lyrics: On the paths we used to roam,', 'Complete these lyrics: As the rain washes over,', 'Complete these lyrics: With the songs of the ancients,']\n"]}],"source":["# Define a Python list to hold the songwriting prompts\n","song_prompts = [\n","    \"Complete these lyrics: Underneath the stars that\",\n","    \"Complete these lyrics: When the rain starts falling and\",\n","    \"Complete these lyrics: Beside the flowing river where\",\n","    \"Complete these lyrics: Amid the echoes of the old town, the\",\n","    \"Complete these lyrics: As the leaves turn golden, there\",\n","    \"Complete these lyrics: Through the winding streets of my memories,\",\n","    \"Complete these lyrics: Under the shadow of the old bridge, we\",\n","    \"Complete these lyrics: When the lights go out and\",\n","    \"Complete these lyrics: Across the endless sea, the wind\",\n","    \"Complete these lyrics: Beneath the wide sky where\",\n","    \"Complete these lyrics: Along the path less traveled by,\",\n","    \"Complete these lyrics: Beyond the horizon where dreams\",\n","    \"Complete these lyrics: Through the whispering fields of green,\",\n","    \"Complete these lyrics: On the balcony at midnight, I\",\n","    \"Complete these lyrics: In the silence of the morning,\",\n","    \"Complete these lyrics: Beside the crackling fire, we\",\n","    \"Complete these lyrics: When the curtain falls and\",\n","    \"Complete these lyrics: In the deepest of forests,\",\n","    \"Complete these lyrics: Beneath the bustling city lights,\",\n","    \"Complete these lyrics: With every heartbeat, I\",\n","    \"Complete these lyrics: As the storm clouds gather,\",\n","    \"Complete these lyrics: Amidst the fading colors of the sunset,\",\n","    \"Complete these lyrics: Under the spell of the full moon,\",\n","    \"Complete these lyrics: Along the frozen shores,\",\n","    \"Complete these lyrics: Between the pages of a forgotten book,\",\n","    \"Complete these lyrics: Beneath the starry sky, as\",\n","    \"Complete these lyrics: Wrapped in the cold night air,\",\n","    \"Complete these lyrics: In the quiet hours before dawn,\",\n","    \"Complete these lyrics: On the edge of a dream, where\",\n","    \"Complete these lyrics: Under the burning sun that\",\n","    \"Complete these lyrics: Within the walls of this ancient castle,\",\n","    \"Complete these lyrics: Beyond the fields that\",\n","    \"Complete these lyrics: Underneath the weight of this world,\",\n","    \"Complete these lyrics: As the river flows and\",\n","    \"Complete these lyrics: Through the valley of shadows,\",\n","    \"Complete these lyrics: In the grip of the cold winter,\",\n","    \"Complete these lyrics: Amidst the clashing of our words,\",\n","    \"Complete these lyrics: On the streets where history\",\n","    \"Complete these lyrics: With the fading light of the evening,\",\n","    \"Complete these lyrics: In the hush of the night, where\",\n","    \"Complete these lyrics: By the old mill stream where\",\n","    \"Complete these lyrics: As the clock strikes midnight,\",\n","    \"Complete these lyrics: Beyond the misty mountains,\",\n","    \"Complete these lyrics: Through the sorrow and the pain,\",\n","    \"Complete these lyrics: In the echo of ancient chants,\",\n","    \"Complete these lyrics: On a journey to nowhere,\",\n","    \"Complete these lyrics: Amidst the crowds of yesterday,\",\n","    \"Complete these lyrics: In the mirror's reflection, I\",\n","    \"Complete these lyrics: At the break of dawn,\",\n","    \"Complete these lyrics: Where the wild roses grow,\",\n","    \"Complete these lyrics: In the gleam of the fading light,\",\n","    \"Complete these lyrics: By the calm waters of the lake,\",\n","    \"Complete these lyrics: Beneath the veil of twilight,\",\n","    \"Complete these lyrics: On the wings of the morning,\",\n","    \"Complete these lyrics: Through the storm and the rain,\",\n","    \"Complete these lyrics: As the world turns slowly,\",\n","    \"Complete these lyrics: Beneath the ancient oak,\",\n","    \"Complete these lyrics: On the road that leads to nowhere,\",\n","    \"Complete these lyrics: In the depths of your eyes,\",\n","    \"Complete these lyrics: At the end of the journey,\",\n","    \"Complete these lyrics: With the whisper of the wind,\",\n","    \"Complete these lyrics: Under the canopy of stars,\",\n","    \"Complete these lyrics: In the labyrinth of my thoughts,\",\n","    \"Complete these lyrics: When the shadows fall and\",\n","    \"Complete these lyrics: As we dance through the night,\",\n","    \"Complete these lyrics: On the shores of a distant land,\",\n","    \"Complete these lyrics: In the twilight of our years,\",\n","    \"Complete these lyrics: With each passing storm,\",\n","    \"Complete these lyrics: By the fading embers of the fire,\",\n","    \"Complete these lyrics: Through the pages of our days,\",\n","    \"Complete these lyrics: Under the veil of the night sky,\",\n","    \"Complete these lyrics: In the whispers of the forgotten,\",\n","    \"Complete these lyrics: At the edge of the sea,\",\n","    \"Complete these lyrics: Where the streets have no name,\",\n","    \"Complete these lyrics: In the flow of the endless river,\",\n","    \"Complete these lyrics: As the stars begin to gather,\",\n","    \"Complete these lyrics: On the brink of the unknown,\",\n","    \"Complete these lyrics: Within the echoes of silence,\",\n","    \"Complete these lyrics: Through the mist and the darkness,\",\n","    \"Complete these lyrics: Underneath the cascade of falling leaves,\",\n","    \"Complete these lyrics: As the fireflies light the night,\",\n","    \"Complete these lyrics: By the light of the silvery moon,\",\n","    \"Complete these lyrics: Amidst the ruins of once-great cities,\",\n","    \"Complete these lyrics: On the breath of the morning breeze,\",\n","    \"Complete these lyrics: In the shadow of the setting sun,\",\n","    \"Complete these lyrics: Through the dance of the firelight,\",\n","    \"Complete these lyrics: On the paths we used to roam,\",\n","    \"Complete these lyrics: As the rain washes over,\",\n","    \"Complete these lyrics: With the songs of the ancients,\"\n","]\n","\n","# Print out the list or perform any other operations you need with it\n","print(song_prompts)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate using ChatGPT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI(\n","    api_key=\"OPENAPIKEY\",\n",")\n","\n","def compare_lyrics(lyrics1, lyrics2):\n","    prompt_text = f\"Here are two sets of song lyrics:\\n\\nLyrics A:\\n{lyrics1}\\n\\nLyrics B:\\n{lyrics2}\\n\\nWhich set of lyrics do you think is better?\"\n","    \n","    chat_completion = client.chat.completions.create(\n","        messages=[\n","            {\n","                \"role\": \"user\",\n","                \"content\": prompt_text,\n","            }\n","        ],\n","        model=\"gpt-3.5-turbo\",\n","    )\n","\n","#     print(response.choices[0].text.strip())\n","    print(chat_completion.choices[0].message)\n","    \n","    \n","prompt = \"Complete this lyric about love and loss:\"\n","# Load models and tokenizer\n","model_base = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","text_generator_finetuned = pipeline('text-generation', model=model_path, tokenizer=model_path)\n","generated_lyrics_finetuned = text_generator_finetuned(prompt, max_length=500, truncation=True)[0]['generated_text']\n","\n","text_generator_base = pipeline('text-generation', model=model_base, tokenizer=tokenizer)\n","generated_lyrics_base = text_generator_base(prompt, max_length=500, truncation=True)[0]['generated_text']\n","\n","# Call the function to compare the lyrics\n","compare_lyrics(generated_lyrics_base, generated_lyrics_finetuned)\n","# Lyrics A is the first parameter, Lyrics B is the second parameter"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["['Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics A', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics B', 'Lyrics A', 'Lyrics A', 'Lyrics A', 'Lyrics A']\n","Our Model was chosen 79.7752808988764% of the time.\n"]}],"source":["from openai import OpenAI\n","import logging\n","import numpy as np\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n","\n","client = OpenAI(\n","    api_key=\"OPENAPIKEY\",\n",")\n","\n","logging.getLogger().setLevel(logging.ERROR)\n","\n","def compare_lyrics(lyrics1, lyrics2):\n","    prompt_text = f\"Here are two sets of song lyrics:\\n\\nLyrics A:\\n{lyrics1}\\n\\nLyrics B:\\n{lyrics2}\\n\\nWhich set of lyrics do you think is better (for your answer, just put your response ex. Lyrics _)?\"\n","    \n","    chat_completion = client.chat.completions.create(\n","        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n","        model=\"gpt-3.5-turbo\",\n","    )\n","    return chat_completion.choices[0].message.content\n","\n","### gpt model stuff\n","model_base = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","### fine tuned model stuff\n","checkpoint_path = './models'\n","model_fine_tuned = GPT2LMHeadModel.from_pretrained(checkpoint_path)\n","tokenizer_fine_tuned = GPT2Tokenizer.from_pretrained(checkpoint_path)\n","\n","text_generator_base = pipeline('text-generation', model=model_base, tokenizer=tokenizer)\n","text_generator_finetuned = pipeline('text-generation', model=model_fine_tuned, tokenizer=tokenizer_fine_tuned)\n","results = []\n","\n","for prompt in song_prompts:\n","    generated_lyrics_finetuned = text_generator_finetuned(prompt, max_length=500, truncation=True)[0]['generated_text']\n","    generated_lyrics_base = text_generator_base(prompt, max_length=500, truncation=True)[0]['generated_text']\n","    result = compare_lyrics(generated_lyrics_base, generated_lyrics_finetuned)\n","    results.append(result)\n","    \n","print(results)\n","\n","choices_count = np.mean([r == 'Lyrics B' for r in results])\n","print(f\"Our Model was chosen {choices_count * 100}% of the time.\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":174593070,"sourceType":"kernelVersion"},{"isSourceIdPinned":true,"modelInstanceId":34588,"sourceId":41107,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelInstanceId":34603,"sourceId":41124,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
